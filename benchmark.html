---
layout: default
title: Pangool Benchmark
---
<div class="hero-unit">
	<h1>Pangool Benchmark</h1>
</div>

<p>
In order to demonstrate that Pangool performs comparable to Hadoop, we have designed a benchmark and executed it in EC2.
This benchmark has been updated as of <strong>9th of March of 2012</strong>.
</p>
<div class="alert">
We take this benchmark seriously. We have made all its details publicly available so if you find something wrong or have any comment you can just tell us or submit a pull request. You can run this benchmark anytime by following its instructions and if you find something weird, please tell us. 
</div>
<p>
We have used <a href='http://whirr.apache.org/'>Whirr 0.7.1</a> to instantiate a CDH3 cluster with 4 m1.large slave nodes and 1 master node. We used the following properties:
</p>
<pre>
whirr.cluster-name=cdh-cluster
whirr.instance-templates=1 hadoop-jobtracker+hadoop-namenode+ganglia-monitor+ganglia-metad,4 hadoop-datanode+hadoop-tasktracker+ganglia-monitor
whirr.provider=aws-ec2
whirr.hadoop.install-function=install_cdh_hadoop
whirr.hadoop.configure-function=configure_cdh_hadoop
whirr.hardware-id=m1.large
</pre>
<p>
We have executed three different examples with three different input sizes. Each of the examples were launched in a <strong>comparable
implementation in Hadoop, Crunch and Cascading</strong>. You can see the implementations in the <a href='https://github.com/datasalt/pangool-benchmark'>pangool-benchmark project</a>. 
If you find <strong>something wrong, please send us your feedback. You are free to suggest alternative implementations that could perform better</strong>.
</p>
<div class="alert">
We have considered <a href='https://github.com/cloudera/crunch'>Crunch</a> and <a href='http://www.cascading.org/'>Cascading</a> for this benchmark in order to have more data points. 
They are, however, different APIs that were conceived with other requirements in mind. Pangool aims to be a replacament of the low-level MapReduce Hadoop Java API, whereas both Crunch and Cascading abstract the user from MapReduce - which allows them to implement easier flow management, something that Pangool doesn't (yet) aim for.
</div>
<p>
For Cascading, we used the 1.2.5 stable release. For Crunch, we built the 0.2.0 version in 2012-02 and used Avro serialization
because we found it to be much more efficient than TupleWritables.
</p> 
<p>
You'll find <a href='https://github.com/datasalt/pangool-benchmark/blob/master/launch-benchmark.sh'>a script in pangool-benchmark</a> that launches the full benchmark. Please read the header before launching it to
make sure you meet all the conditions for launching it.
</p>

<h2>Url Resolution</h2>

<p>
The <a href='https://github.com/datasalt/pangool/blob/master/examples/src/main/java/com/datasalt/pangool/examples/urlresolution/UrlResolution.java'>Url Resolution example in Pangool</a> shows how to perform a reduce-side join easily. We have implemented alternative versions of this example
in <a href='https://github.com/datasalt/pangool-benchmark/blob/master/src/main/java/com/datasalt/pangool/benchmark/urlresolution/HadoopUrlResolution.java'>Hadoop</a>, <a href='https://github.com/datasalt/pangool-benchmark/blob/master/src/main/java/com/datasalt/pangool/benchmark/urlresolution/CrunchUrlResolution.java'>Crunch</a> and <a href='https://github.com/datasalt/pangool-benchmark/blob/master/src/main/java/com/datasalt/pangool/benchmark/urlresolution/CascadingUrlResolution.java'>Cascading</a> (click to see each of them).
</p>
<p>
For generating the input datasets, we used the following commands (you'll find them in the launch-benchmark.sh script we mentioned above):
</p>
<pre>
hadoop jar $PANGOOL_EXAMPLES_JAR url_resolution_gen_data url-map-1.txt url-reg-1.txt 1000 10 1000
hadoop jar $PANGOOL_EXAMPLES_JAR url_resolution_gen_data url-map-2.txt url-reg-2.txt 5000 10 1000
hadoop jar $PANGOOL_EXAMPLES_JAR url_resolution_gen_data url-map-3.txt url-reg-3.txt 5000 50 1000
</pre>
<p>
These are the results that we obtained in time (seconds) and IO (bytes):
</p>
<p>
<img src='images/benchmark/ur_t.png'/>
<img src='images/benchmark/ur_io.png'/>
</p>
<p>
We can see that all implementations had a comparable IO footprint. However, we clearly see that Pangool and Hadoop are much closer in efficiency than Crunch or Avro. In this case Pangool performed 8% worse than Hadoop, Crunch 27% and Cascading 70%.
</p>
<h2>Secondary sort</h2>

<p>
The <a href='https://github.com/datasalt/pangool/blob/master/examples/src/main/java/com/datasalt/pangool/examples/secondarysort/SecondarySort.java'>Secondary Sort example in Pangool</a> shows how to perform a secondary sort using multiple fields easily. We have implemented alternative versions of this
example in <a href='https://github.com/datasalt/pangool-benchmark/blob/master/src/main/java/com/datasalt/pangool/benchmark/secondarysort/HadoopSecondarySort.java'>Hadoop</a>, <a href='https://github.com/datasalt/pangool-benchmark/blob/master/src/main/java/com/datasalt/pangool/benchmark/secondarysort/CrunchSecondarySort.java'>Crunch</a> and <a href='https://github.com/datasalt/pangool-benchmark/blob/master/src/main/java/com/datasalt/pangool/benchmark/secondarysort/CascadingSecondarySort.java'>Cascading</a>.
</p>
<p>
For generating the input datasets, we used the following commands (you'll find them in the launch-benchmark.sh script we mentioned above):
</p>
<pre>
hadoop jar $PANGOOL_EXAMPLES_JAR secondarysort_gen_data secondarysort-1.txt 100 100 1000
hadoop jar $PANGOOL_EXAMPLES_JAR secondarysort_gen_data secondarysort-2.txt 200 200 2000
hadoop jar $PANGOOL_EXAMPLES_JAR secondarysort_gen_data secondarysort-3.txt 300 300 3000
</pre>
<p>
These are the results that we obtained in time (seconds) and IO (bytes):
</p>
<p>
<img src='images/benchmark/ss_t.png'/>
<img src='images/benchmark/ss_io.png'/>
</p>
<p>
In this example Hadoop and Pangool are both close in efficiency and IO footprint. However, Cascading deviates considerably in both aspects. Pangool performed 5% worse than Hadoop, Crunch 28% and Cascading 181%.
</p>

<h2>Standard Word Count</h2>

<p>
We used the default Word Count implementations of all APIs for this last benchmark. Because Word Count is a quite simple problem that doesn't involve joins or secondary sort, we are measuring here the most basic API overhead.
Click to see the implementations for <a href='https://github.com/datasalt/pangool-benchmark/blob/master/src/main/java/com/datasalt/pangool/benchmark/wordcount/PangoolWordCount.java'>Pangool</a>, <a href='https://github.com/datasalt/pangool-benchmark/blob/master/src/main/java/com/datasalt/pangool/benchmark/wordcount/HadoopWordCount.java'>Hadoop</a>, <a href='https://github.com/datasalt/pangool-benchmark/blob/master/src/main/java/com/datasalt/pangool/benchmark/wordcount/CrunchWordCount.java'>Crunch</a> and <a href='https://github.com/datasalt/pangool-benchmark/blob/master/src/main/java/com/datasalt/pangool/benchmark/wordcount/CascadingWordCount.java'>Cascading</a>.
</p>
<p>
For generating the input datasets, we used the following commands (you'll find them in the launch-benchmark.sh script we mentioned above):
</p>
<pre>
hadoop jar $PANGOOL_BENCHMARK_JAR wordcount_gen_data wordcount-1.txt 1000000 50 4
hadoop jar $PANGOOL_BENCHMARK_JAR wordcount_gen_data wordcount-2.txt 5000000 50 4
hadoop jar $PANGOOL_BENCHMARK_JAR wordcount_gen_data wordcount-3.txt 10000000 50 4
</pre>
<p>
These are the results that we obtained in time (seconds) and IO (bytes):
</p>
<p>
<img src='images/benchmark/wc_t.png'/>
<img src='images/benchmark/wc_io.png'/>
</p>
<p>
We can see that in this case Hadoop, Pangool (5% worse) and Crunch (9% worse) performed similarly.
</p>
<p>
In this case, Cascading's overhead (257%) is not very meaningful because its default Word Count implementation doesn't include the use of its in-memory combiners whereas the other implementations (Pangool, Hadoop, Crunch) are already using Combiners.
<p>

<h1>Conclusions</h1>

<p>
We have seen how <strong>Pangool performs comparable to Hadoop</strong> in three different cases, performing <strong>between only 5 and 8% worse</strong> 
according to this benchmark. Except for the word count example - where Pangool code is larger than Hadoop's word count 
becase we can't reuse the Combiner as we are not writing Tuples as output - the implementations in Pangool <strong>are much 
more concise and easy than those of Hadoop</strong>, which are extremely complex because of the use of custom Comparators, 
custom data types and other boilerplate code.
</p> 
<p>
Overall, <strong>in code conciseness, Cascading wins in all of the examples, but its performance is in other orders of magnitude. This is understandable, since Cascading is a higher-level API that solves a lot of problems that neither Hadoop or Pangool solve</strong>.
</p>
<p> 
On the other hand, we have found Crunch to perform very good when used in conjunction with Avro. It is an interesting API because it solves higher-level problems like flow management while retaining a decent performance. However, we found the resulting code for both the Url Resolution and Secondary Sort example to be extremely complex and hard to maintain. 
</p>  