---
layout: default
title: Pangool - Overview
name: overview
---
<div class="hero-unit">
	<p>
		<h2>Overview</h2>
		<p>
			Pangool is an open-source implementation of - what we call -
			 <a href="http://www.datasalt.com/2012/02/tuple-mapreduce-beyond-the-classic-mapreduce/">
			 Tuple Map/Reduce</a> based on the Hadoop Java MapReduce API.
		</p>
	</p>	
</div>

<h2>Introduction</h2>
<p>
Pangool is a <strong>Java, low-level MapReduce API</strong>. It aims to be a <strong>replacement</strong> for the 
Hadoop Java MapReduce API. By implementing an intermediate Tuple-based schema and 
configuring a Job conveniently, <strong>many of the accidental complexities that arise from using 
the Hadoop Java MapReduce API disappear</strong>. Things like secondary sort and reduce-side joins 
become extremely easy to implement and understand. Pangool's performance is comparable to that 
of the Hadoop Java MapReduce API. Pangool also augments Hadoop's API by making multiple outputs 
and inputs first-class and allowing instance-based configuration.
</p>

<hr>
<div class="alert-message">
Pangool is compatible with Hadoop 0.20.2 and all prior versions, including <a href='https://ccp.cloudera.com/display/CDHDOC/CDH3+Quick+Start+Guide'>Cloudera's CDH3</a> and <a href='http://www.mapr.com/'>MapR</a>.
</div>
<hr>

<h2>Features</h2>
<p>
<div class="row">
	<div class="span8 well">
		<h3>Intermediate Tuple-based serialization</h3>
		<p>
			By using Tuples instead of (key, value) pairs, the user is not forced to write their 
			custom data types (e.g. Writables) or use external serialization libraries when working 
			with more than two fields.		
		</p>
		<p>
		However Pangool’s Tuples may contain arbitrary data types - as long as they are serializable by Hadoop.
		</p>
	</div>
	<div class="span8 well">
		<h3>Efficient, easy-to-use secondary sorting</h3>
		<p>
			In Pangool you can say <code>groupBy(“user”, “country”)</code>, <code>sortBy(“user”, “country”, “name”)</code>. Pangool 
			will use an intelligent and efficient Partitioner, Sort and Group Comparator underneath just like an 
			advanced user would do with the plain Hadoop MapReduce API.
		</p>
	</div>
</div> 
 
<div class="row">
	<div class="span8 well">
		<h3>Efficient, easy-to-use reduce-side joins</h3>
		<p>
			Doing reduce-side joins with Pangool is as simple as it can get. By using 
			Tuples and configuring your MapReduce jobs properly, you can easily join various 
			datasets and perform arbitrary business logic on them. Again, Pangool will know how 
			to partition, sort and group by underneath in an efficient way.		
		<p>
	</div>
	<div class="span8 well">
		<h3>Instance-based configuration</h3>
		<p>
			Mapper, Combiner, Reducers, Input / Output Formats and Comparators can be passed 
			via object instance. Pangool will serialize the instance into the DistributedCache 
			and reinstantiate the object when needed. This way, boilerplate configuration code is 
			no longer needed.
		</p>
	</div>
</div>

<div class="row">
	<div class="span8 well">
		<h3>First-class multiple inputs / outputs</h3>
		<p>
			Multiple inputs & outputs in Pangool is part of its standard API.		
		<p>
	</div>
	<div class="span8 well">
		<h3>Input / Output Tuple formats</h3>
		<p>
			Tuples may be persisted and used as input to other Jobs by using 
			TupleOutputFormat / TupleInputFormat which use Avro underneath for serializing.		
		</p>
	</div>
</div>


<div class="row">
	<div class="span8 well">
		<h3>Performance and flexibility</h3>
		<p>
			Pangool is an alternative to the Java Hadoop MapReduce API. The same things can be 
			achieved by using one or another. Pangool’s performance is quite close to that of 
			Hadoop’s MapReduce API (<a href='benchmark.html'>see our benchmark with other tools for a reference</a>). Pangool 
			just makes life easier to those that require the efficiency and flexibility of 
			the plain Java Hadoop MapReduce API.		
		<p>
	</div>
</div>
</p>

<p><a class="btn primary large" href="getting_started.html">Get started &raquo;</a></p>
 



